{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dac40ea-cf10-4e46-93bb-5df853414c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style = \"whitegrid\",font_scale=1.4)\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6437d9-e346-4bbe-9e99-ff881ab0fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.expanduser('~'), 'Library/CloudStorage/Box-Box', 'COVID-19 Adolphs Lab','PreProcessed_Data')\n",
    "selResp_path = os.path.join(os.path.expanduser('~'), 'Library/CloudStorage/Box-Box', 'COVID-19 Adolphs Lab','core_analysis','self_response')\n",
    "out_dir = os.path.expanduser('~/Library/CloudStorage/Box-Box/COVID-19 Adolphs Lab/core_analysis/external_selfResp_combined')\n",
    "fig_dir = os.path.expanduser('~/Library/CloudStorage/Box-Box/COVID-19 Adolphs Lab/core_analysis/figures')\n",
    "core_data_path = os.path.join(os.path.expanduser('~'), 'Library/CloudStorage/Box-Box', 'COVID-19 Adolphs Lab','core_analysis','processed_data')\n",
    "\n",
    "data_file = 'Wave1-18_A-N_release.csv'\n",
    "data = pd.read_csv(os.path.join(data_path, data_file), low_memory=False, na_values='NaN', dtype = str)\n",
    "# include only full prlfc waves \n",
    "data = data.loc[data.wave.isin(['1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                                '10', '11', '12', '13', '14', '15', '16', '17']), :]\n",
    "\n",
    "# add week numbers for more accurate temproal representation of waves\n",
    "wave_to_week = pd.read_csv(os.path.join(selResp_path, 'wave_to_week.csv'),dtype = str)\n",
    "wave_dict = {wave_to_week.loc[i, 'wave']:wave_to_week.loc[i, 'wave_week'] for i in wave_to_week.index}\n",
    "data['week'] = data['wave'].copy() \n",
    "data.week.replace(wave_dict, inplace = True)\n",
    "data = data.astype({'wave': 'float', 'week': 'float'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aac0f1",
   "metadata": {},
   "source": [
    "# Maximum Variation Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384fa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# code from Yanting Han: https://github.com/adolphslab/CovidDynamic_dataRelease/blob/main/figures-tables/TempTrends_ExmplVars%20/IDforplot.py\n",
    "# Farthest point sampling\n",
    "def calc_distances(p0, points):\n",
    "    return np.sqrt(((p0 - points)**2.).sum(axis=1))\n",
    "\n",
    "def farthest_points(pts, pt_labels, K,ii):\n",
    "    ndims = pts.shape[1] #5 dims\n",
    "    farthest_pts = np.zeros((K, ndims)) # specify format for wanted points, 5/10 people*5 dim\n",
    "    farthest_pts[0] = pts[ii]  \n",
    "    farthest_pts_labs = []\n",
    "    farthest_pts_labs.append(pt_labels[ii]) # append label \n",
    "    distances = calc_distances(farthest_pts[0], pts) # calculate dist for this subject with all other ones\n",
    "\n",
    "    for ij in range(1, K):\n",
    "        farthest_pts[ij] = pts[np.argmax(distances)] #returns the index of the subject with the furthest dist\n",
    "        farthest_pts_labs.append(pt_labels[np.argmax(distances)])\n",
    "        distances = np.minimum(distances, calc_distances(farthest_pts[ij], pts))\n",
    "        # for the rest of the points, update the distance to be the min to the already chosen ones\n",
    "    return farthest_pts, farthest_pts_labs\n",
    "\n",
    "# maximum variation sampling (eucl.-dist)\n",
    "def max_var_sampling(value_array, id_lables, K):\n",
    "    all_sols_dists = []\n",
    "    all_sols_feats = []\n",
    "    all_sols_names = []\n",
    "    for iter_ii in range(value_array.shape[0]):\n",
    "        solution_set, solution_labels = farthest_points(value_array,id_lables,K, iter_ii)\n",
    "        all_sols_feats.append(solution_set)\n",
    "        all_sols_names.append(solution_labels)\n",
    "        all_sols_dists.append(np.sum(pdist(solution_set, metric='euclidean')))\n",
    "\n",
    "    best_sols_feats = all_sols_feats[np.argmax(all_sols_dists)]\n",
    "    best_sols_labels = all_sols_names[np.argmax(all_sols_dists)]\n",
    "    return best_sols_feats, best_sols_labels\n",
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e063555-2131-4ece-9213-6081497e6034",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d45024-6144-4c1b-912b-bb29f7f3bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables semantically \n",
    "data[['DemC8','DemC9','DemM6','DemW5','DemC23']] = data[['DemC8','DemC9','DemM6','DemW5','DemC23']].astype('float')\n",
    "data['ethnicity'] = data['DemC8']\n",
    "data['race'] = data['DemC9']\n",
    "data['ethnicity'] = data['ethnicity'].replace({1: 'Hispanic or Latino', 2: 'Not Hispanic or Latino',3:' Prefer not to disclose'})\n",
    "data['race'] = data['race'].replace({1:'American Indian/Alaska Native', 2:'Asian', 3:'Native Hawaiian or Other Pacific Islander',\n",
    "                                          4: 'Black or African American', 5: 'White', 6: 'Multiracial', 7:'Other', 8: 'Prefer not to disclose'})\n",
    "data['polit_party'] = data['DemM6']\n",
    "data['polit_party'] = data['polit_party'].replace({1:'Republican', 2: 'Democrat', 3: 'Independent',  4: 'Other'})\n",
    "data['sex'] = data['prlfc_dem_sex'].copy()\n",
    "data['pop_density'] = data['DemW5']\n",
    "# invert population density variable (9-> center of a big city, high population density, 1-> rural, low population denisty )\n",
    "data['pop_density'] = 10-data['pop_density']  \n",
    "# 1= Some high school; 2 = High school; 3 = Some college; 4 = Associate's degree; 5 = Bachelor's degree; 6 = Some graduate education; 7 = Master's degree; 8 = PhD; 9 = Professional degree; 10 = Other (please specify)\t\n",
    "data['education'] = data['DemC23'].copy()\n",
    "data = data.sort_values(by=['PROLIFIC_PID','wave'])\n",
    "data['education'] = data['education'].ffill()\n",
    "data = data.rename(columns = {'prlfc_dem_age': 'age'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4555712",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2401524226.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/fc/_2yc799j3dq5tc6c7h7f9z5c0000gn/T/ipykernel_9537/2401524226.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    DemW18_R1\tinteger\t1::7\tWhat was your weekly income (in U.S. $) last week?\t1 = Less than $249; 2 = $250 - $499; 3 = $500 - $999; 4 = $1000 -$1499; 5 = $1500 - $2999; 6 = more than $3000 ; 7 = Don't know\t\tx\u001b[0m\n\u001b[0m             \t^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "DemW18_R1\tinteger\t1::7\tWhat was your weekly income (in U.S. $) last week?\t1 = Less than $249; 2 = $250 - $499; 3 = $500 - $999; 4 = $1000 -$1499; 5 = $1500 - $2999; 6 = more than $3000 ; 7 = Don't know\t\tx\t\t\t\t\n",
    "DemW18_R2\tinteger\t1::9\tWhat was your weekly income (in U.S. $) last week?\t1 = None; 2 = $1 - $99; 3 = $100 - $249; 4 = $250 - $499; 5 = $500 - $999; 6 = $1000 - $1499; 7 = $1500 - $2999; 8 = more than $3000; 9 = Don't know\t\t\tx\tx\tx\tx\n",
    "DemW18.1\tinteger\t1::9\tWhat was your total household weekly income (in U.S. $) last week?\t1 = None; 2 = $1 - $99; 3 = $100 - $249; 4 = $250 - $499; 5 = $500 - $999; 6 = $1000 - $1499; 7 = $1500 - $2999; 8 = more than $3000; 9 = Don't know\t\t\t\t\t\t\n",
    "DemW18.2\tinteger\t1::9\tWhat was your individual weekly income (in U.S. $) last week?\t1 = None; 2 = $1 - $99; 3 = $100 - $249; 4 = $250 - $499; 5 = $500 - $999; 6 = $1000 - $1499; 7 = $1500 - $2999; 8 = more than $3000; 9 = Don't know\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab109b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine weekly income variables\n",
    "data[[\"DemW18_R1\",\"DemW18_R2\",\n",
    "      \"DemW18.2\", \"DemW18.1\"]] = data[[\"DemW18_R1\",\"DemW18_R2\",\n",
    "                                       \"DemW18.2\",\"DemW18.1\"]].astype(float)\n",
    "\n",
    "DemW18_R1_dict =  {1: \"<$250\", \n",
    "                   2: \"$250 - $499\",\n",
    "                   3: \"$500 - $999\", \n",
    "                   4: \"$1000 -$1499\", \n",
    "                   5: \"$1500 - $2999\", \n",
    "                   6: \">$3000\", \n",
    "                   7: \"Don't know\"}\n",
    "\n",
    "data[\"DemW18_R1\"] = data[\"DemW18_R1\"].replace(DemW18_R1_dict)\n",
    "\n",
    "DemW18_R2_dict =  {1: \"<$250\", \n",
    "                   2: \"<$250\", \n",
    "                   3: \"<$250\", \n",
    "                   4: \"$250 - $499\",\n",
    "                   5: \"$500 - $999\", \n",
    "                   6: \"$1000 -$1499\", \n",
    "                   7: \"$1500 - $2999\", \n",
    "                   8: \">$3000\", \n",
    "                   9: \"Don't know\"}          \n",
    "data[\"DemW18_R2\"] = data[\"DemW18_R2\"].replace(DemW18_R2_dict)\n",
    "\n",
    "\n",
    "data['weekly_income_gen_1'] = data['DemW18_R1'].copy()\n",
    "data['weekly_income_gen_2'] = data['DemW18_R2'].copy()\n",
    "\n",
    "\n",
    "DemW18_2_dict  =  {1: \"<$250\", \n",
    "                   2: \"<$250\", \n",
    "                   3: \"<$250\", \n",
    "                   4: \"$250 - $499\",\n",
    "                   5: \"$500 - $999\", \n",
    "                   6: \"$1000 -$1499\", \n",
    "                   7: \"$1500 - $2999\", \n",
    "                   8: \">$3000\", \n",
    "                   9: \"Don't know\"}             \n",
    "data[\"DemW18.2\"] = data[\"DemW18.2\"].replace(DemW18_2_dict)\n",
    "data['weekly_income_indiv'] = data[\"DemW18.2\"].copy()\n",
    "\n",
    "\n",
    "DemW18_2_dict  =  {1: \"<$250\", \n",
    "                   2: \"<$250\", \n",
    "                   3: \"<$250\", \n",
    "                   4: \"$250 - $499\",\n",
    "                   5: \"$500 - $999\", \n",
    "                   6: \"$1000 -$1499\", \n",
    "                   7: \"$1500 - $2999\", \n",
    "                   8: \">$3000\", \n",
    "                   9: \"Don't know\"}             \n",
    "data[\"DemW18.1\"] = data[\"DemW18.1\"].replace(DemW18_2_dict)\n",
    "data['weekly_income_household'] = data[\"DemW18.1\"].copy()\n",
    "\n",
    "income_cat_dict = {\"<$250\":250,  \n",
    "                   \"$250 - $499\":499,\n",
    "                   \"$500 - $999\":999, \n",
    "                   \"$1000 -$1499\":1499, \n",
    "                   \"$1500 - $2999\":2999, \n",
    "                   \">$3000\":4499, \n",
    "                   \"Don't know\":np.nan}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[['weekly_income_gen_1', \n",
    "      'weekly_income_gen_2', \n",
    "      'weekly_income_indiv',\n",
    "      'weekly_income_household']] = data[['weekly_income_gen_1', \n",
    "                                          'weekly_income_gen_2', \n",
    "                                          'weekly_income_indiv',\n",
    "                                          'weekly_income_household']].replace(income_cat_dict)\n",
    "\n",
    "data.loc[data.wave == 1, 'weekly_income_gen'] = data.loc[data.wave == 1, 'weekly_income_gen_1'] \n",
    "data.loc[data.wave > 1, 'weekly_income_gen'] = data.loc[data.wave > 1, 'weekly_income_gen_2'] \n",
    "\n",
    "data[['wave','PROLIFIC_PID','weekly_income_gen',  'weekly_income_indiv','weekly_income_household']]\n",
    "\n",
    "data.loc[data.wave ==17, ['weekly_income_gen','weekly_income_indiv','weekly_income_household']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dd9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa04313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.loc[data.wave == 1, \"weekly_income_self\"] = data.loc[data.wave == 1, \"DemW18_R1\"] \n",
    "data.loc[data.wave.isin([2,3,4,5,6]), \"weekly_income_self\"] = data.loc[data.wave.isin([2,3,4,5,6]),\"DemW18_R2\"] \n",
    "data.loc[data.wave.isin([7,8,9,10,11,12,\n",
    "                         13,14,15,16,17]), \"weekly_income_self\"] = data.loc[data.wave.isin([7,8,9,10,11,12,\n",
    "                                                                                            13,14,15,16,17]),\"DemW18.2\"]\n",
    "\n",
    "\n",
    "data = data.rename(columns = {\"DemW18.1\": 'weekly_income_household'})\n",
    "\n",
    "data['weekly_income_self_cat'] = data.weekly_income_self.copy()\n",
    "\n",
    "income_med_dict = {\"<$250\":125,  \n",
    "                   \"$250 - $499\":350,\n",
    "                   \"$500 - $999\":750, \n",
    "                   \"$1000 -$1499\":1250, \n",
    "                   \"$1500 - $2999\":1750, \n",
    "                   \">$3000\":4000, \n",
    "                   \"Don't know\":np.nan}\n",
    "data['weekly_income_self_cat_num'] = data['weekly_income_self_cat'].replace(income_cat_dict)\n",
    "data['weekly_income_self_med_num'] = data['weekly_income_self_cat'].replace(income_med_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710741aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "717c9e67-9b1c-4314-88f2-a0c23aa00ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SAFETY MEASURES ADOPTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0b1e6-666c-4d3e-a0e0-2e84c9bdd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT COLLECTED IN W18\n",
    "safety_measures = []\n",
    "for idx in range(1,10):\n",
    "    safety_measures.append('RW22_' + str(idx))\n",
    "# additional self-restriction questions    \n",
    "    \n",
    "# questions scored as 1 or NaN --> re-lable NaN as 0 if question was included in wave\n",
    "for w in data.wave.unique():\n",
    "    for col in safety_measures:\n",
    "        if ~data.loc[data.wave == w, col].isnull().all():\n",
    "            data.loc[data.wave == w, col] = data.loc[data.wave == w, col].fillna(0)\n",
    "            \n",
    "data['safety_measures'] = data[safety_measures].astype(float).mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b72f2a-573d-446d-adc0-a0a878c45413",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Personal CVD Concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654c771-2f2f-40f4-971d-ee714659d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_concerns = []\n",
    "for idx in range(9,13):\n",
    "    cvd_concerns.append('RW' + str(idx)) \n",
    "data['cvd_concern'] = data[cvd_concerns].astype(float).mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbdeaf-6e2b-46cd-ab7d-f841a51a06a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CVD Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cb666-ec91-4152-a20a-fd62bb8c8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_norm = [] \n",
    "for idx in range(2,5): \n",
    "    cvd_norm.append('norm' + str(idx)) \n",
    "data['cvd_norm_agreement'] = data[cvd_norm].astype(float).mean(axis = 1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220af05-af05-45d7-8719-c9830555ed53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Restriction importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80d4dc-ea87-4b1e-b084-9da6a3df22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 factors: factor items and loadings\n",
    "factor1_dict = {\"RW26_1\": 0.664, # Restricting gatherings to fewer than 10 people\n",
    "                \"RW26_2\": 0.536, #Closing schools\n",
    "                \"RW26_3\":0.756, #Closing restaurants / bars\n",
    "                \"RW26_17\":0.790, #Restricting gatherings to fewer than 5 people\n",
    "                \"RW26_18\":0.727, #Restricting gatherings to no more than 2 people\n",
    "                \"RW26_10\":0.654, #Cancelling church services and other meetings\n",
    "                \"RW26_11\":0.757, #Staying home, except to fulfill essential needs, like buying food and medicine.\n",
    "                \"RW26_12\":0.857, #Closing non-essential businesses\n",
    "                \"RW26_13\":0.808, #Closing parks and other public outdoor places\n",
    "                \"RW26_14\":0.597} #Wearing masks when in public\n",
    "\n",
    "factor2_dict = {\"RW26_15\":1.009,  #Restricting gatherings to fewer than 250 people\n",
    "                \"RW26_16\":0.925} #Restricting gatherings to fewer than 50 people\n",
    "\n",
    "factor3_dict = {\"RW26_4\": 0.676, #Avoiding contact with people who are sick\n",
    "                \"RW26_5\":0.698, #Staying home when you are sick (except to get medical care)\n",
    "                \"RW26_6\": 0.783, #Covering coughs and sneezes\n",
    "                \"RW26_7\":0.534} #Washing hands often\n",
    "\n",
    "# flip responses: original = 1 = Necessary; 2 = Not necessary, but probably helpful; 3 = Probably not helpful; 4 = A major over-reaction \n",
    "# flip so that 1 --> low importance and 4 --> high importance\n",
    "cols = list(factor1_dict.keys()) + list(factor2_dict.keys()) + list(factor3_dict.keys())\n",
    "factors = data[['week','wave','PROLIFIC_PID']].copy()\n",
    "factors.week = factors.week.astype(int)\n",
    "factors.wave = factors.wave.astype(int)\n",
    "factors[cols] = 5 - data[cols].astype(float) \n",
    "\n",
    "# factor 1\n",
    "for fItem in factor1_dict.keys():\n",
    "    #factors[fItem] = factors[fItem]*factor1_dict[fItem]\n",
    "    factors[fItem] = factors[fItem]\n",
    "\n",
    "data['restrict_f1'] = factors[factor1_dict.keys()].mean(axis=1)\n",
    "\n",
    "# factor 2\n",
    "for fItem in factor2_dict.keys():\n",
    "    #factors[fItem] = factors[fItem]*factor2_dict[fItem]  \n",
    "    factors[fItem] = factors[fItem]\n",
    "\n",
    "data['restrict_f2'] = factors[factor2_dict.keys()].mean(axis=1)\n",
    "\n",
    "# factor 3\n",
    "for fItem in factor3_dict.keys():\n",
    "    #factors[fItem] = factors[fItem]*factor3_dict[fItem] \n",
    "    factors[fItem] = factors[fItem]\n",
    "\n",
    "data['restrict_f3'] = factors[factor3_dict.keys()].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd27bc8-f70a-41f2-bb98-810fb3e6377d",
   "metadata": {},
   "source": [
    "# init summary scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9564e5f-8d73-4f20-a597-faf54eb6aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attitude_measures = ['cvd_concern', 'cvd_norm_agreement','restrict_f1', 'restrict_f2', 'restrict_f3']\n",
    "impact_measures  = ['weekly_income_self_cat_num','safety_measures',\n",
    "                    'parent_health_impact',  \n",
    "                    'grandparent_health_impact',\n",
    "                    'thirdDegree_health_impact', \n",
    "                    'child_health_impact', \n",
    "                    'friend_health_impact',\n",
    "                    'work_colleague_health_impact',\n",
    "                    'sibling_health_impact']\n",
    "\n",
    "summary_scores = data[['week','wave','PROLIFIC_PID', \n",
    "                      'ethnicity', 'race','polit_party', 'sex','agecats','education','age',\n",
    "                       'weekly_income_self_cat_num','weekly_income_self_cat','weekly_income_self_med_num','weekly_income_household',\n",
    "                      'safety_measures', 'cvd_concern', 'cvd_norm_agreement',\n",
    "                      'restrict_f1', 'restrict_f2', 'restrict_f3']].copy()\n",
    "summary_scores.week = summary_scores.week.astype(int)\n",
    "summary_scores.wave = summary_scores.wave.astype(int)\n",
    "\n",
    "# Demographic variables\n",
    "summary_scores = summary_scores.sort_values(['PROLIFIC_PID', 'wave'])\n",
    "summary_scores['polit_party'] = summary_scores['polit_party'].ffill()\n",
    "summary_scores['ethnicity'] = summary_scores['ethnicity'].ffill()\n",
    "summary_scores['race'] = summary_scores['race'].ffill()\n",
    "summary_scores['sex'] = summary_scores['sex'].ffill()\n",
    "summary_scores['age'] = summary_scores['age'].ffill()\n",
    "\n",
    "summary_scores['agecats'] = summary_scores['agecats'].ffill()\n",
    "summary_scores = summary_scores.loc[summary_scores[['ethnicity','race','polit_party','sex','agecats','weekly_income_self_cat_num']].notna().sum(axis=1)>5, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008dc4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_scores.wave.unique()\n",
    "summary_scores[['ethnicity','race','polit_party','sex','agecats','weekly_income_self_cat_num']].notna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d749c2",
   "metadata": {},
   "source": [
    "# COVID  attitude measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape attitude measures for maximum variation sampling \n",
    "\n",
    "max_var_concern = data.loc[:,['PROLIFIC_PID', 'week','wave','cvd_concern']]\n",
    "max_var_concern = max_var_concern.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'cvd_concern')\n",
    "max_var_concern = max_var_concern.dropna(axis = 0)\n",
    "\n",
    "max_var_norm = data.loc[:,['PROLIFIC_PID', 'week','cvd_norm_agreement']]\n",
    "max_var_norm = max_var_norm.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'cvd_norm_agreement')\n",
    "max_var_norm = max_var_norm.dropna(axis = 0)\n",
    "\n",
    "max_var_f1 = data.loc[:,['PROLIFIC_PID', 'week','restrict_f1']]\n",
    "max_var_f1 = max_var_f1.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'restrict_f1')\n",
    "max_var_f1 = max_var_f1.dropna(axis = 0)\n",
    "\n",
    "max_var_f2 = data.loc[:,['PROLIFIC_PID', 'week','restrict_f2']]\n",
    "max_var_f2 = max_var_f2.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'restrict_f2')\n",
    "max_var_f2 = max_var_f2.iloc[:,2:]\n",
    "max_var_f2 = max_var_f2.dropna(axis = 0)\n",
    "\n",
    "max_var_f3 = data.loc[:,['PROLIFIC_PID', 'week','restrict_f3']]\n",
    "max_var_f3 = max_var_f3.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'restrict_f3')\n",
    "max_var_f3 = max_var_f3.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum variation sampling on COVID health concerns\n",
    "K = 5\n",
    "value_array = max_var_concern.values\n",
    "id_lables = max_var_concern.index\n",
    "best_sols_feats, best_sols_labels = max_var_sampling(value_array, id_lables, K)\n",
    "most_dist = max_var_concern.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# within-wave variance\n",
    "fig, axs = plt.subplots(2,3, figsize = (25,10))\n",
    "axs_flat = axs.flatten()\n",
    "\n",
    "y_vars = ['cvd_concern', 'cvd_norm_agreement', 'restrict_f1','restrict_f2', 'restrict_f3']\n",
    "y_label = ['COVID health concerns (a.u.)', 'COVID norm agreement (a.u.)', \n",
    "           'public restriction\\nimportance (a.u.)', \n",
    "           'large gathering\\nrestriction importance (a.u.)', \n",
    "           'pers. hygiene (a.u.)']\n",
    "\n",
    "for idx, y in enumerate(y_vars):\n",
    "    sns.boxplot(data = summary_scores, x = 'wave', y = y, ax = axs_flat[idx])\n",
    "    axs_flat[idx].set_ylabel( y_label[idx])\n",
    "    \n",
    "img_format = 'svg'\n",
    "fig.savefig(os.path.join(fig_dir, 'attitude_within_wave_spread.' + img_format), format=img_format)\n",
    "\n",
    "var_df= summary_scores[['cvd_concern', 'cvd_norm_agreement', 'restrict_f1','restrict_f2', 'restrict_f3','wave']].groupby(by = 'wave').var()\n",
    "var_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6979b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_scores_zscore = summary_scores.copy()\n",
    "\n",
    "for y in y_vars:\n",
    "    summary_scores_zscore[y_vars] = (summary_scores_zscore[y_vars] -summary_scores_zscore[y_vars].mean())/summary_scores_zscore[y_vars].std()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (5,5.5))\n",
    "x_label = ['COVID health\\nconcerns', 'COVID norm\\nagreement', \n",
    "           'public restriction\\nimportance', \n",
    "           'large gathering\\nrestriction importance', \n",
    "           'pers. hygiene']\n",
    "\n",
    "# Within subject variance across waves per measure\n",
    "sns.boxplot(summary_scores[['cvd_concern', 'cvd_norm_agreement', 'restrict_f1','restrict_f2', 'restrict_f3','PROLIFIC_PID']].groupby(by = 'PROLIFIC_PID').var(), ax = ax,\n",
    "            palette = [[1,0.1,0.3]])\n",
    "sns.stripplot(summary_scores[['cvd_concern', 'cvd_norm_agreement', 'restrict_f1','restrict_f2', 'restrict_f3','PROLIFIC_PID']].groupby(by = 'PROLIFIC_PID').var(), ax = ax, \n",
    "                palette='dark:black', alpha = 0.3)\n",
    "ax.set_xticklabels( x_label,rotation = 90, fontsize = 15);\n",
    "ax.set_ylim((-0.1,1.5));\n",
    "ax.set_ylabel('within subject var.',fontsize = 15)\n",
    "\n",
    "img_format = 'svg'\n",
    "fig.savefig(os.path.join(fig_dir, 'withinSubVar_attitudes.' + img_format), format=img_format)\n",
    "\n",
    "\n",
    "var_df= summary_scores[['cvd_concern', 'cvd_norm_agreement', 'restrict_f1','restrict_f2', 'restrict_f3','PROLIFIC_PID']].groupby(by = 'PROLIFIC_PID').var()\n",
    "var_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fd877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize COVID  attitude measures\n",
    "fig, axs = plt.subplots(1,3, figsize = (35,5))\n",
    "fig.suptitle('Attitude Measures',  fontsize = 40)\n",
    "fig.text(0.05, 1, 'C', verticalalignment='top', horizontalalignment='left',  fontsize = 50)\n",
    "\n",
    "\n",
    "## cvd_concern\n",
    "most_dist = max_var_concern.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "sns.lineplot(data = summary_scores, x = 'week', y ='cvd_concern', color=[1,0.1,0.3], \n",
    "             linewidth=5,linestyle = ':',  ax = axs[0], errorbar=('sd')) \n",
    "sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "             ax = axs[0], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "axs[0].set_xticks(summary_scores.week.unique())\n",
    "axs[0].set_xticklabels(summary_scores.wave.unique(), fontsize = 15)\n",
    "axs[0].set_xlabel('wave',fontsize = 20)\n",
    "axs[0].set_ylim([0.9,5.1])\n",
    "axs[0].set_ylabel('COVID health concerns (a.u.)',fontsize = 20)\n",
    "axs[0].set_xlim([0.5,69.5])\n",
    "\n",
    "\n",
    "## cvd_norm_agreement\n",
    "most_dist = max_var_norm.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "sns.lineplot(data = summary_scores, x = 'week', y = 'cvd_norm_agreement', color=[1,0.1,0.3], \n",
    "             linewidth=5, linestyle = ':',  ax = axs[1], errorbar=('sd')) \n",
    "sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "             ax = axs[1], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "axs[1].set_xticks(summary_scores.week.unique()); \n",
    "axs[1].set_xticklabels(summary_scores.wave.unique(), fontsize = 15); \n",
    "axs[1].set_xlabel('wave', fontsize = 20); \n",
    "axs[1].set_ylim([0.9,5.1]); \n",
    "axs[1].set_ylabel('COVID norm agreement (a.u.)', fontsize = 20); \n",
    "axs[1].set_xlim([0.5,69.5])\n",
    "\n",
    "\n",
    "## public restriction importance \n",
    "most_dist = max_var_f1.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "sns.lineplot(data = summary_scores, x = 'week', y = 'restrict_f1', color=[1,0.1,0.3], \n",
    "             linewidth=5, linestyle = ':',  ax = axs[2], errorbar=('sd')) \n",
    "sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "             ax = axs[2], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "axs[2].set_xticks(summary_scores.week.unique()); \n",
    "axs[2].set_xticklabels(summary_scores.wave.unique(), fontsize = 15); \n",
    "axs[2].set_xlabel('wave', fontsize = 20); \n",
    "axs[2].set_ylabel('public restrict. import. (a.u.)', fontsize = 20); \n",
    "axs[2].set_ylim([0.9,4.1])\n",
    "axs[2].set_xlim([0.5,69.5])\n",
    "\n",
    "\n",
    "# ## large gatherings restrict. import.\n",
    "# most_dist = max_var_f2.loc[best_sols_labels].copy()\n",
    "# most_dist = most_dist.T\n",
    "# most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "# sns.lineplot(data = summary_scores, x = 'week', y = 'restrict_f2', color=[1,0.1,0.3], \n",
    "#              linewidth=5,linestyle = ':',  ax = axs[1,1], errorbar=('sd')) \n",
    "# sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "#              ax = axs[1,1], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "# axs[1,1].set_xticks(summary_scores.week.unique()); \n",
    "# axs[1,1].set_xticklabels(summary_scores.wave.unique(), fontsize = 15); \n",
    "# axs[1,1].set_xlabel('wave', fontsize = 20); \n",
    "# axs[1,1].set_ylabel('large gatherings\\nrestrict. import. (a.u.)', fontsize = 20); \n",
    "# axs[1,1].set_ylim([0.9,4.1])\n",
    "# axs[1,1].set_xlim([0.5,69.5])\n",
    "\n",
    "\n",
    "# ## personal hygiene import.\n",
    "# most_dist = max_var_f3.loc[best_sols_labels].copy()\n",
    "# most_dist = most_dist.T\n",
    "# most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "# sns.lineplot(data = summary_scores, x = 'week', y = 'restrict_f3', color=[1,0.1,0.3], \n",
    "#              linewidth=5, linestyle = ':',  ax = axs[1,2], errorbar=('pi')) \n",
    "# sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "#              ax = axs[1,2], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "# axs[1,2].set_xticks(summary_scores.week.unique()); \n",
    "# axs[1,2].set_xticklabels(summary_scores.wave.unique(), fontsize = 15); \n",
    "# axs[1,2].set_xlabel('wave', fontsize = 20); \n",
    "# axs[1,2].set_ylabel('personal hygiene\\nimport. (a.u.)',  fontsize = 20); \n",
    "# axs[1,2].set_ylim([0.9,4.1])\n",
    "# axs[1,2].set_xlim([0.5,69.5])\n",
    "\n",
    "\n",
    "img_format = 'svg'\n",
    "fig.savefig(os.path.join(fig_dir, 'timecourse_CVD_attitudes.' + img_format), format=img_format)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f29882-1688-423c-9862-a8dbc1892cae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Personal Experience Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caba223-6e30-4d02-b2f4-123282cbf374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOCIAL NETWORK HEALTH IMPACT\n",
    "def health_impact(col_nameV1,col_nameV2,  soc_cat, data, out_data):\n",
    "    '''\n",
    "    Health impact in the social network was assesed in two differnt variables (w1-8: RW21; w9-18: RW21v2)\n",
    "    This function combines the two variabales and creates a summary score for the defined social category.\n",
    "    @ Input:\n",
    "    col_nameV1 (string): V1 data column, e.g. \"RW21_1\" --> spouse\n",
    "    col_nameV2 (string): V2 data column, e.g. \"RW21v2_1\" --> spouse\n",
    "    soc_cat (string): label for social category, e.g. \"spouse_health_impact\"\n",
    "    data (df): all data dataframe\n",
    "    out_data (df): summary output dataframe\n",
    "    '''\n",
    "    \n",
    "    tmp_cols = []\n",
    "    for idx in range(2,6):\n",
    "        tmp_cols.append(col_nameV1 + '_' + str(idx))\n",
    "        tmp_cols.append(col_nameV2 + '_' + str(idx))\n",
    "\n",
    "    tmp_cols = ['PROLIFIC_PID', 'wave'] + tmp_cols\n",
    "    tmp_data = data[tmp_cols].copy()  \n",
    "\n",
    "    tmp_data_w1_8 = tmp_data.columns[(tmp_data.columns.str.startswith('RW21_')) & (~tmp_data.columns.str.endswith('1'))]\n",
    "    tmp_data_w9_18 = tmp_data.columns[(tmp_data.columns.str.startswith('RW21v2_'))& (~tmp_data.columns.str.endswith('1'))]\n",
    "\n",
    "\n",
    "    tmp_data = tmp_data.fillna(0)\n",
    "    for idx, col in enumerate(tmp_data_w1_8):\n",
    "         tmp_data.loc[tmp_data[col] == '1.0', col] = idx+1\n",
    "    for idx, col in enumerate(tmp_data_w9_18):\n",
    "         tmp_data.loc[tmp_data[col] == '1.0', col] = idx+1        \n",
    "    out_data[soc_cat] = tmp_data.iloc[:,2:].max(axis=1)\n",
    "    return out_data\n",
    "\n",
    "summary_scores = health_impact('RW21_1' ,'RW21v2_1',  'spouse_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_2' ,'RW21v2_2',  'parent_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_3' ,'RW21v2_3',  'grandparent_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_4' ,'RW21v2_4',  'thirdDegree_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_5' ,'RW21v2_5',  'child_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_6' ,'RW21v2_6',  'friend_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_7' ,'RW21v2_7',  'work_colleague_health_impact', data, summary_scores)\n",
    "summary_scores = health_impact('RW21_9' ,'RW21v2_9',  'sibling_health_impact', data, summary_scores)\n",
    "\n",
    "\n",
    "tmp_data = summary_scores[['PROLIFIC_PID','week','wave',\n",
    "                           'spouse_health_impact', \n",
    "                           'parent_health_impact', \n",
    "                           'grandparent_health_impact',\n",
    "                           'thirdDegree_health_impact', \n",
    "                           'child_health_impact', \n",
    "                           'friend_health_impact',\n",
    "                           'work_colleague_health_impact',\n",
    "                           'sibling_health_impact']].melt(id_vars=['PROLIFIC_PID',\n",
    "                                                                  'week', \n",
    "                                                                  'wave'], value_vars=['spouse_health_impact', \n",
    "                                                                                       'parent_health_impact',\n",
    "                                                                                       'grandparent_health_impact',\n",
    "                                                                                       'thirdDegree_health_impact', \n",
    "                                                                                       'child_health_impact', \n",
    "                                                                                       'friend_health_impact',\n",
    "                                                                                       'work_colleague_health_impact',\n",
    "                                                                                       'sibling_health_impact'])\n",
    "\n",
    "# summarize social network health impact \n",
    "summary_scores.loc[:,'mean_social_network_health'] = summary_scores[['spouse_health_impact', 'parent_health_impact',\n",
    "                                                 'grandparent_health_impact','sibling_health_impact', \n",
    "                                                 'thirdDegree_health_impact','child_health_impact', \n",
    "                                                 'friend_health_impact','work_colleague_health_impact']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape COVID experience measures for maximum variation sampling \n",
    "\n",
    "max_var_safety_measures = summary_scores.loc[:,['PROLIFIC_PID', 'week','wave','safety_measures']]\n",
    "max_var_safety_measures = max_var_safety_measures.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'safety_measures')\n",
    "max_var_safety_measures = max_var_safety_measures.dropna(axis = 0)\n",
    "\n",
    "max_var_weekly_income = summary_scores.loc[:,['PROLIFIC_PID', 'week','weekly_income_self_cat_num']]\n",
    "max_var_weekly_income = max_var_weekly_income.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'weekly_income_self_cat_num')\n",
    "max_var_weekly_income = max_var_weekly_income.dropna(axis = 0)\n",
    "\n",
    "max_var_mean_social_network_health = summary_scores.loc[:,['PROLIFIC_PID', 'week','mean_social_network_health']]\n",
    "max_var_mean_social_network_health = max_var_mean_social_network_health.pivot(index = 'PROLIFIC_PID', columns = ['week'], values = 'mean_social_network_health')\n",
    "max_var_mean_social_network_health = max_var_mean_social_network_health.dropna(axis = 0)\n",
    "\n",
    "K = 5\n",
    "value_array = max_var_safety_measures.values\n",
    "id_lables = max_var_safety_measures.index\n",
    "best_sols_feats, best_sols_labels = max_var_sampling(value_array, id_lables, K)\n",
    "most_dist = max_var_safety_measures.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize COVID  experience measures\n",
    "fig, axs = plt.subplots(1,3, figsize = (35,5))\n",
    "fig.suptitle('Personal Experience Measures',  fontsize = 40)\n",
    "fig.text(0.05, 1, 'B', verticalalignment='top', horizontalalignment='left',  fontsize = 50)\n",
    "\n",
    "\n",
    "## mean social network health \n",
    "most_dist = max_var_mean_social_network_health.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "sns.lineplot(data = summary_scores, x ='week',  y = 'mean_social_network_health', color=[0.4,0.8,0.7], \n",
    "             linewidth=5, linestyle = ':',  ax = axs[0], errorbar=('sd')) \n",
    "sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "             ax = axs[0], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "axs[0].set_xticks(summary_scores.week.unique());\n",
    "axs[0].set_xticklabels(summary_scores.wave.unique(), fontsize = 15);\n",
    "axs[0].set_xlabel('wave', fontsize = 20)\n",
    "axs[0].set_xlim([0.5,69.5])\n",
    "axs[2].set_ylim([-0.01,4.1])\n",
    "axs[0].set_ylabel('COVID health impact\\non social network (a.u.)', fontsize = 20)\n",
    "handles, labels = axs[2].get_legend_handles_labels()\n",
    "\n",
    "\n",
    "\n",
    "## personal weekly income\n",
    "most_dist = max_var_weekly_income.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "# reverse income for plotting\n",
    "most_dist['value'] = summary_scores.weekly_income_self_cat_num.max()+1 - most_dist['value']\n",
    "summary_scores['weekly_income_self_cat_num_reverse'] = summary_scores.weekly_income_self_cat_num.max()+1 -summary_scores.weekly_income_self_cat_num\n",
    "\n",
    "sns.lineplot(data = summary_scores, x = 'week', y = 'weekly_income_self_cat_num_reverse', color=[0.4,0.8,0.7], \n",
    "             linewidth=5, linestyle = ':',  ax = axs[1], errorbar=('pi')) \n",
    "sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "             ax = axs[1], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "axs[1].set_xticks(summary_scores.week.unique());\n",
    "axs[1].set_xticklabels(summary_scores.wave.unique(), fontsize = 15);\n",
    "axs[1].set_xlabel('wave', fontsize = 20)\n",
    "axs[1].set_xlim([0.5,69.5])\n",
    "axs[1].set_ylabel('weekly income reversed\\n($4000-weekly income)', fontsize = 20);\n",
    "axs[1].tick_params(axis='x', labelsize=12)\n",
    "axs[1].set_ylim([0,4000])\n",
    "\n",
    "\n",
    "## safety measures adopted\n",
    "most_dist = max_var_safety_measures.loc[best_sols_labels].copy()\n",
    "most_dist = most_dist.T\n",
    "most_dist = pd.DataFrame(most_dist.stack()).reset_index().rename(columns = {0:'value'})\n",
    "\n",
    "sns.lineplot(data = summary_scores, x = 'week', y = 'safety_measures', color=[0.4,0.8,0.7], \n",
    "             linewidth=5, linestyle = ':',  ax = axs[2], errorbar=('sd')) \n",
    "sns.lineplot(data = most_dist, x = 'week', y = 'value', hue ='PROLIFIC_PID', \n",
    "             ax = axs[2], linewidth=2.5,palette = \"Set2\", legend=False)\n",
    "axs[2].set_xticks(summary_scores.week.unique());\n",
    "axs[2].set_xticklabels(summary_scores.wave.unique(), fontsize = 15);\n",
    "axs[2].set_xlabel('wave', fontsize = 20)\n",
    "axs[2].set_xlim([0.5,69.5])\n",
    "axs[2].set_ylabel('restrictions of\\npersonal behavior (a.u.)', fontsize = 20);\n",
    "axs[2].set_ylim([-0.01,1.1])\n",
    "axs[2].tick_params(axis='x', labelsize=12)\n",
    "axs[2].yaxis.label.set_size(20)\n",
    "axs[2].xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "img_format = 'svg'\n",
    "fig.savefig(os.path.join(fig_dir, 'timecourse_CVD_impact.' + img_format), format=img_format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f8639-74ba-40ef-87b6-1dc08692d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save summary scores\n",
    "summary_scores.to_csv(os.path.join(out_dir, 'CVD_core_summary_scores.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c459f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVD-datapaper",
   "language": "python",
   "name": "cvd-datapaper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
