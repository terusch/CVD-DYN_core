{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac15319-2a23-4ed5-885f-84d0051d51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import numpy.matlib "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e1e73",
   "metadata": {},
   "source": [
    "see https://osf.io/7xnju/ for external data\n",
    "\n",
    "\n",
    "PID data not publically available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a559dd-1bfc-4209-b967-e2bce84295d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = os.path.expanduser(os.path.join('~','Library','CloudStorage','Box-Box', 'COVID-19 Adolphs Lab', 'core_analysis', 'raw_data'))\n",
    "out_path = os.path.expanduser(os.path.join('~','Library','CloudStorage','Box-Box', 'COVID-19 Adolphs Lab', 'core_analysis', 'processed_data'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb692e7c-babd-465a-8c30-0d686db70bc5",
   "metadata": {},
   "source": [
    "# Wave dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42592b01-38de-473e-bae9-a184fa440491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "wave_date = pd.read_csv(os.path.join(data_path, 'wave_dates.csv'), dtype = 'str')\n",
    "wave_date.start_date = wave_date.start_date.astype('datetime64[ns]')\n",
    "wave_date.next_monday = wave_date.next_monday.astype('datetime64[ns]')\n",
    "for days in range(1,8):\n",
    "    wave_date['start_date-' + str(days)] = wave_date.start_date - timedelta(days=days)\n",
    "wave_date.drop(columns = ['next_monday'], inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d9673",
   "metadata": {},
   "source": [
    "# PID DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe449e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output state and county data frame for states and counties included in participant data\n",
    "pid_county = pd.read_csv(os.path.join(out_path,'participant_county_data.csv'), dtype = 'str')\n",
    "\n",
    "# exclude subjects with non-informative county data\n",
    "pid_county = pid_county.loc[pid_county.flag !='9.0', :]\n",
    "pid_county = pid_county.merge(wave_date, on=['wave'])\n",
    "pid_county.drop(columns = ['zip_code','moved','nearest_town', 'county_by_zip', 'county_by_city_and_state', 'county_man_edit'], inplace = True)\n",
    "pid_county = pd.melt(pid_county, id_vars=['PROLIFIC_PID','wave','state','county','loc_description','flag'], value_vars=['start_date','start_date-1',\n",
    "                                                                                                  'start_date-2','start_date-3',\n",
    "                                                                                                  'start_date-4','start_date-5',\n",
    "                                                                                                  'start_date-6','start_date-7'])\n",
    "pid_county.rename(columns = {'variable': 'wave_day', 'value': 'date'}, inplace = True)\n",
    "pid_county.county = pid_county.county.str.replace(' county', '')\n",
    "pid_county.county = pid_county.county.str.replace('montgomery ', 'montgomery')\n",
    "pid_county.county = pid_county.county.str.replace('baltimore city', 'baltimore')\n",
    "\n",
    "\n",
    "# from April 2020 to December 2021\n",
    "dates_incl = pd.date_range(date.fromisoformat('2020-04-04'), date.fromisoformat('2021-12-31'))\n",
    "\n",
    "# participant state and counties\n",
    "county_data = pid_county[['state','county']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "date_df = pd.DataFrame(np.tile(np.array(dates_incl),(county_data.shape[0],1)))\n",
    "\n",
    "# combine counties and dates\n",
    "county_data = pd.concat([county_data, date_df], axis=1)\n",
    "county_data = county_data.melt(id_vars = ['state', 'county'], value_vars = date_df.columns)\n",
    "county_data = county_data.drop('variable', axis=1)\n",
    "county_data = county_data.rename(columns = {'value':'date'})\n",
    "county_data = county_data.loc[~county_data.county.isna(),:].reset_index(drop = True)\n",
    "state_data = county_data.copy()\n",
    "state_data = state_data.drop('county', axis=1)\n",
    "\n",
    "# state and dates\n",
    "state_data = state_data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# add year, month day, seperatly\n",
    "date_tmp_county = np.array(list(county_data.date.astype('str').str.split('-')))\n",
    "county_data['year'] = date_tmp_county[:,0]\n",
    "county_data['month'] = date_tmp_county[:,1]\n",
    "county_data['day'] = date_tmp_county[:,2]\n",
    "\n",
    "# add year, month day, seperatly\n",
    "date_tmp_state = np.array(list(state_data.date.astype('str').str.split('-')))\n",
    "state_data['year'] = date_tmp_state[:,0]\n",
    "state_data['month'] = date_tmp_state[:,1]\n",
    "state_data['day'] = date_tmp_state[:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4181ad3f-1752-465d-81f2-9a2a5e34f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_dict = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    " 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'DC': 'District of Columbia', \n",
    " 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois',\n",
    " 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', \n",
    " 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota',\n",
    " 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', \n",
    " 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',\n",
    " 'NC': \"North Carolina\", 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    " 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina', \n",
    " 'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', \n",
    " 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', \n",
    " 'WY': 'Wyoming', 'PR': 'Puerto Rico'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcec857",
   "metadata": {},
   "source": [
    "# COVID cases/ deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55027677",
   "metadata": {},
   "source": [
    "state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38e8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state avg\n",
    "covid_avg_state = pd.read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us-states.csv\", dtype = 'str')\n",
    "covid_avg_state.state = covid_avg_state.state.str.lower()\n",
    "covid_avg_state = covid_avg_state.drop('geoid', axis=1)\n",
    "covid_avg_state.date = pd.to_datetime(covid_avg_state.date)\n",
    "covid_avg_state = covid_avg_state.drop_duplicates()\n",
    "\n",
    "\n",
    "# state cumsum\n",
    "covid_cumsum_state = pd.read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\", dtype = 'str')\n",
    "covid_cumsum_state.state = covid_cumsum_state.state.str.lower()\n",
    "covid_cumsum_state = covid_cumsum_state.drop('fips', axis=1)\n",
    "covid_cumsum_state.date = pd.to_datetime(covid_cumsum_state.date)\n",
    "covid_cumsum_state = covid_cumsum_state.rename(columns = {'cases': 'cumsum_cases','deaths': 'cumsum_deaths'})\n",
    "covid_cumsum_state = covid_cumsum_state.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be7548",
   "metadata": {},
   "source": [
    "county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5253e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county avg\n",
    "covid_avg_county_2020 = pd.read_csv(os.path.join(data_path,\"CVDrollingavgs_nytimes_counties2020.csv\"), dtype = 'str')\n",
    "covid_avg_county_2021 = pd.read_csv(os.path.join(data_path,\"CVDrollingavgs_nytimes_counties2021.csv\"), dtype = 'str')\n",
    "covid_avg_county = pd.concat([covid_avg_county_2020, covid_avg_county_2021])\n",
    "covid_avg_county.state = covid_avg_county.state.str.lower()\n",
    "covid_avg_county.county = covid_avg_county.county.str.lower()\n",
    "covid_avg_county = covid_avg_county.drop('geoid', axis=1)\n",
    "covid_avg_county.date = pd.to_datetime(covid_avg_county.date)\n",
    "# manually edit spelling differences\n",
    "covid_avg_county.county = covid_avg_county.county.str.replace('doña ana', 'dona ana')\n",
    "covid_avg_county.county = covid_avg_county.county.str.replace('new york city', 'new york')\n",
    "covid_avg_county.county = covid_avg_county.county.str.replace('anchorage', 'anchorage municipality')\n",
    "covid_avg_county.county = covid_avg_county.county.str.replace('bienville', 'bienville parish')\n",
    "covid_avg_county.county = covid_avg_county.county.str.replace('rapides', 'rapides parish')\n",
    "covid_avg_county.loc[covid_avg_county.county=='st. tammany', 'county'] = 'st. tammany parish'\n",
    "covid_avg_county.loc[(covid_avg_county.county=='lafayette') & ((covid_avg_county.state=='kentucky') | \n",
    "                                                               (covid_avg_county.state=='louisiana')), 'county' ] = 'lafayette parish'\n",
    "covid_avg_county.loc[(covid_avg_county.county=='livingston') & (covid_avg_county.state=='louisiana'), 'county' ] = 'livingston parish'\n",
    "covid_avg_county.loc[(covid_avg_county.county=='orleans') & (covid_avg_county.state=='louisiana'), 'county' ] = 'orleans parish'\n",
    "covid_avg_county.loc[(covid_avg_county.county=='ouachita') & (covid_avg_county.state=='louisiana'), 'county' ] = 'ouachita parish'\n",
    "covid_avg_county.loc[(covid_avg_county.county=='calcasieu') & (covid_avg_county.state=='louisiana'), 'county' ] = 'calcasieu parish'\n",
    "\n",
    "\n",
    "# county cumsum\n",
    "covid_cumsum_county = pd.read_csv(os.path.join(data_path,\"CVDcumsum_nytimes_counties.csv\"), dtype = 'str')\n",
    "covid_cumsum_county.state = covid_cumsum_county.state.str.lower()\n",
    "covid_cumsum_county.county = covid_cumsum_county.county.str.lower()\n",
    "covid_cumsum_county = covid_cumsum_county.drop('fips', axis=1)\n",
    "covid_cumsum_county.date = pd.to_datetime(covid_cumsum_county.date)\n",
    "covid_cumsum_county = covid_cumsum_county.rename(columns = {'cases': 'cumsum_cases','deaths': 'cumsum_deaths'})\n",
    "# manually edit spelling differences\n",
    "covid_cumsum_county.county = covid_cumsum_county.county.str.replace('doña ana', 'dona ana')\n",
    "covid_cumsum_county.county = covid_cumsum_county.county.str.replace('new york city', 'new york')\n",
    "\n",
    "covid_cumsum_county.county = covid_cumsum_county.county.str.replace('anchorage', 'anchorage municipality')\n",
    "covid_cumsum_county.county = covid_cumsum_county.county.str.replace('bienville', 'bienville parish')\n",
    "covid_cumsum_county.county = covid_cumsum_county.county.str.replace('rapides', 'rapides parish')\n",
    "covid_cumsum_county.loc[covid_cumsum_county.county=='st. tammany', 'county'] = 'st. tammany parish'\n",
    "covid_cumsum_county.loc[(covid_cumsum_county.county=='lafayette') & ((covid_cumsum_county.state=='kentucky') | \n",
    "                                                               (covid_cumsum_county.state=='louisiana')), 'county' ] = 'lafayette parish'\n",
    "covid_cumsum_county.loc[(covid_cumsum_county.county=='livingston') & (covid_cumsum_county.state=='louisiana'), 'county' ] = 'livingston parish'\n",
    "covid_cumsum_county.loc[(covid_cumsum_county.county=='orleans') & (covid_cumsum_county.state=='louisiana'), 'county' ] = 'orleans parish'\n",
    "covid_cumsum_county.loc[(covid_cumsum_county.county=='ouachita') & (covid_cumsum_county.state=='louisiana'), 'county' ] = 'ouachita parish'\n",
    "covid_cumsum_county.loc[(covid_cumsum_county.county=='calcasieu') & (covid_cumsum_county.state=='louisiana'), 'county' ] = 'calcasieu parish'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # the NYT includes Bronx and Queens county COVID data in the NYC data --> copying NYC data\n",
    "bronx_county_cumsum = covid_cumsum_county.loc[covid_cumsum_county.county == 'new york'].reset_index(drop = True).copy()\n",
    "bronx_county_cumsum['county'] = 'bronx'\n",
    "bronx_county_avg = covid_avg_county.loc[covid_avg_county.county == 'new york'].reset_index(drop = True).copy()\n",
    "bronx_county_avg['county'] = 'bronx'\n",
    "queens_county_cumsum = covid_cumsum_county.loc[covid_cumsum_county.county == 'new york'].reset_index(drop = True).copy()\n",
    "queens_county_cumsum['county'] = 'queens'\n",
    "queens_county_avg = covid_avg_county.loc[covid_avg_county.county == 'new york'].reset_index(drop = True).copy()\n",
    "queens_county_avg['county'] = 'queens'\n",
    "\n",
    "covid_cumsum_county = pd.concat([covid_cumsum_county, bronx_county_cumsum, queens_county_cumsum])\n",
    "covid_cumsum_county = covid_cumsum_county.drop_duplicates()\n",
    "covid_avg_county = pd.concat([covid_avg_county, bronx_county_avg, queens_county_avg])\n",
    "covid_avg_county = covid_avg_county.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e65000",
   "metadata": {},
   "source": [
    "# UNEMPLOYMENT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452f33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ue_state = pd.read_csv(os.path.join(data_path, 'unemployment_state.csv'), dtype = 'str')\n",
    "ue_state.state = ue_state.state.str.lower()\n",
    "\n",
    "ue_county = pd.read_csv(os.path.join(data_path, 'unemployment_county.csv'), dtype = 'str')\n",
    "ue_county['County Name/State Abbreviation'].replace({'District of Columbia': 'District of Columbia, DC'} , inplace = True)\n",
    "county_state_tmp = np.array(list(ue_county['County Name/State Abbreviation'].str.split(', ')))\n",
    "ue_county['county'] = county_state_tmp[:,0]\n",
    "ue_county.county = ue_county.county.str.lower()\n",
    "ue_county['state'] = county_state_tmp[:,1]\n",
    "ue_county['state'] = ue_county['state'].replace(state_dict)\n",
    "ue_county.state = ue_county.state.str.lower()\n",
    "ue_county = ue_county.drop('County Name/State Abbreviation', axis=1)\n",
    "ue_county.Period = ue_county.Period.str.strip('(p')\n",
    "ue_county.Period.replace({'Dec-21': '21-Dec'}, inplace = True)\n",
    "ue_county.Period = ue_county.Period.str.replace('-Se', '-Sep')\n",
    "period_tmp = np.array(list(ue_county.Period.str.split('-')))\n",
    "ue_county['year'] = period_tmp[:,0]\n",
    "ue_county['month'] = period_tmp[:,1]\n",
    "ue_county.month.replace({'Jan': '01','Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05',\n",
    "                         'Jun': '06', 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10',\n",
    "                         'Nov': '11', 'Dec': '12'}, inplace = True)\n",
    "ue_county.year.replace({'20': '2020','21': '2021', '22': '2022'}, inplace = True)\n",
    "ue_county = ue_county.drop('Period', axis=1)\n",
    "\n",
    "ue_county.county = ue_county.county.str.replace(' county', '')\n",
    "ue_county.county = ue_county.county.str.replace('anchorage borough/municipality', 'anchorage municipality')\n",
    "ue_county.county = ue_county.county.str.replace('denver/city', 'denver')\n",
    "ue_county.county = ue_county.county.str.replace('honolulu/city', 'honolulu')\n",
    "ue_county.county = ue_county.county.str.replace('philadelphia/city', 'philadelphia')\n",
    "ue_county.county = ue_county.county.str.replace('san francisco/city', 'san francisco' )\n",
    "\n",
    "ue_county = ue_county.drop_duplicates()\n",
    "ue_state = ue_state.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1e322-8f98-41e9-80bb-b7d49e3c0a3f",
   "metadata": {},
   "source": [
    "# Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9518b5-e7c4-4f79-8374-b8328c311518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stay at home orders\n",
    "stay_at_home_county = pd.read_csv(os.path.join(data_path, \n",
    "                                               'U.S._State_and_Territorial_Stay-At-Home_Orders__March_15__2020___August_15__2021_by_County_by_Day.csv'),\n",
    "                                              low_memory=False, dtype = 'str')\n",
    "drop_cols = ['FIPS_State', 'FIPS_County', 'URL', 'Citation', 'Source_of_Action', 'Express_Preemption']\n",
    "stay_at_home_county.drop(columns = drop_cols, inplace = True)\n",
    "stay_at_home_county.rename(columns= {'State_Tribe_Territory': 'state', 'County_Name': 'county',\n",
    "                                    'Stay_at_Home_Order_Recommendation': 'stayHome_action',\n",
    "                                   'Order_code': 'stayHome_order_code'}, inplace = True)\n",
    "stay_at_home_county.state = stay_at_home_county.state.replace(state_dict)\n",
    "stay_at_home_county = stay_at_home_county.loc[stay_at_home_county.state.isin(list(state_dict.values())),:].reset_index(drop=True)\n",
    "# order code:\n",
    "# (1) - 'Mandatory for all individuals'\n",
    "# (2) - 'Mandatory only for all individuals in certain areas of the jurisdiction'\n",
    "# (3) - 'Mandatory only for at-risk individuals in the jurisdiction'\n",
    "# (4) - missing\n",
    "# (5) - 'Mandatory only for at-risk individuals in certain areas of the jurisdiction'\n",
    "# (6) - 'Advisory/Recommendation'\n",
    "# (7) - 'NaN'\n",
    "\n",
    "############################\n",
    "# gathering ban\n",
    "gather_ban_county = pd.read_csv(os.path.join(data_path, \n",
    "                                               'U.S._State_and_Territorial_Gathering_Bans__March_11__2020-August_15__2021_by_County_by_Day.csv'),\n",
    "                                              low_memory=False, dtype = 'str')\n",
    "drop_cols = ['FIPS_State', 'FIPS_County', 'URL', 'Express_Preemption', 'Citation', 'Source_of_Action', 'URL']\n",
    "gather_ban_county.drop(columns = drop_cols, inplace = True)\n",
    "gather_ban_county.rename(columns= {'State_Tribe_Territory': 'state', 'County_Name': 'county',\n",
    "                                    'General_GB_order_group': 'gatherBan_action',\n",
    "                                    'General_GB_order_code': 'gatherBan_order_code',\n",
    "                                    'General_or_Under_6ft_Bans_Gatherings_Over': 'gatherBan_N_limit',\n",
    "                                    'Indoor_Outdoor': 'gatherBan_indoor_outdoor'}, inplace = True)\n",
    "gather_ban_county.state = gather_ban_county.state.replace(state_dict)\n",
    "gather_ban_county = gather_ban_county.loc[gather_ban_county.state.isin(list(state_dict.values())),:].reset_index(drop=True)\n",
    "\n",
    "# order code:\n",
    "# (1) - 'No order found'\n",
    "# (2) - 'Ban of gatherings over 101 or more people'\n",
    "# (3) - 'Ban of gatherings over 51-100 people'\n",
    "# (4) - 'Ban of gatherings over 26-50 people'\n",
    "# (5) - 'Ban of gatherings over 11-25 people'\n",
    "# (6) - 'Ban of gatherings over 1-10 people'\n",
    "# (7) - 'Bans gatherings of any size'\n",
    "\n",
    "############################\n",
    "# face masks requried ban\n",
    "mask_mandate_county = pd.read_csv(os.path.join(data_path, \n",
    "                                               'U.S._State_and_Territorial_Public_Mask_Mandates_From_April_10__2020_through_August_15__2021_by_County_by_Day.csv'),\n",
    "                                              low_memory=False, dtype = 'str')\n",
    "drop_cols = ['FIPS_State', 'FIPS_County', 'URL', 'Citation', 'Source_of_Action', 'URL']\n",
    "mask_mandate_county.drop(columns = drop_cols, inplace = True)\n",
    "mask_mandate_county.rename(columns= {'State_Tribe_Territory': 'state', 'County_Name': 'county',\n",
    "                                    'order_code': 'mask_order_code',\n",
    "                                    'Face_Masks_Required_in_Public': 'mask_required_in_public'}, inplace = True)\n",
    "\n",
    "mask_mandate_county.state = mask_mandate_county.state.replace(state_dict)\n",
    "mask_mandate_county = mask_mandate_county.loc[mask_mandate_county.state.isin(list(state_dict.values())),:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# order code - Face_Masks_Required_in_Public:\n",
    "# (1) - 'Yes'\n",
    "# (2) - 'NaN'\n",
    "\n",
    "############################\n",
    "# restaurant closures\n",
    "rest_closure_county = pd.read_csv(os.path.join(data_path, \n",
    "                                               'U.S._State_and_Territorial_Orders_Closing_and_Reopening_Restaurants_Issued_from_March_11__2020_through_August_15__2021_by_County_by_Day.csv'),\n",
    "                                              low_memory=False, dtype = 'str')\n",
    "drop_cols = ['FIPS_State', 'FIPS_County', 'Business_Type', 'URL', 'Citation', 'Source_of_Action']\n",
    "rest_closure_county.drop(columns = drop_cols, inplace = True)\n",
    "rest_closure_county.rename(columns= {'State_Tribe_Territory': 'state', 'County_Name': 'county', \n",
    "                                     'Action': 'rest_action', 'order_code': 'rest_order_code',\n",
    "                                    'Percent_Capacity_Outdoor': 'rest_%_capacity_outdoor',\n",
    "                                    'Percent_Capacity_Indoor': 'rest_%_capacity_indoor',\n",
    "                                    'Numeric_Capacity_Outdoor': 'rest_N_capacity_outdoor',\n",
    "                                    'Numeric_Capacity_Indoor': 'rest_N_capacity_indoor',\n",
    "                                    'Limited_Open_Outdoor_Only': 'rest_lim_capacity_outdoor',\n",
    "                                    'Limited_Open_General_Indoor': 'rest_lim_general_indoor'}, inplace = True)\n",
    "rest_closure_county.state = rest_closure_county.state.replace(state_dict)\n",
    "rest_closure_county = rest_closure_county.loc[rest_closure_county.state.isin(list(state_dict.values())),:].reset_index(drop=True)\n",
    "\n",
    "# order code:\n",
    "# (1) - NaN\n",
    "# (2) - 'Authorized to fully reopen'\n",
    "# (3) - 'Open with social distancing/reduced seating/enhanced sanitation'\n",
    "# (4) - 'Open with social distancing/reduced seating/enhanced sanitation'\n",
    "# (5) - 'Curbside/carryout/delivery only'\n",
    "# (6) - 'Closed'\n",
    "\n",
    "############################\n",
    "# bar closures\n",
    "bar_closure_county = pd.read_csv(os.path.join(data_path, \n",
    "                                               'U.S._State_and_Territorial_Orders_Closing_and_Reopening_Bars_Issued_from_March_11__2020_through_August_15__2021_by_County_by_Day.csv'),\n",
    "                                              low_memory=False, dtype = 'str')\n",
    "drop_cols = ['FIPS_State', 'FIPS_County', 'Business_Type', 'URL', 'Citation', 'Source_of_Action']\n",
    "bar_closure_county.drop(columns = drop_cols, inplace = True)\n",
    "bar_closure_county.rename(columns= {'State_Tribe_Territory': 'state', 'County_Name': 'county', \n",
    "                                    'Action': 'bar_action', 'order_code': 'bar_order_code',\n",
    "                                    'Percent_Capacity_Outdoor': 'bar_%_capacity_outdoor',\n",
    "                                    'Percent_Capacity_Indoor': 'bar_%_capacity_indoor',\n",
    "                                    'Numeric_Capacity_Outdoor': 'bar_N_capacity_outdoor',\n",
    "                                    'Numeric_Capacity_Indoor': 'bar_N_capacity_indoor',\n",
    "                                    'Limited_Open_Outdoor_Only': 'bar_lim_capacity_outdoor',\n",
    "                                    'Limited_Open_General_Indoor': 'bar_lim_general_intdoor'}, inplace = True)\n",
    "bar_closure_county.state = bar_closure_county.state.replace(state_dict)\n",
    "bar_closure_county = bar_closure_county.loc[bar_closure_county.state.isin(list(state_dict.values())),:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# order code:\n",
    "# (1) - NaN\n",
    "# (2) - 'Authorized to fully reopen'\n",
    "# (3) - 'Open with social distancing/reduced seating/enhanced sanitation'\n",
    "# (4) - 'Open with social distancing/reduced seating/enhanced sanitation'\n",
    "# (5) - 'Curbside/carryout/delivery only'\n",
    "# (6) - 'Closed'\n",
    "\n",
    "############################\n",
    "restrictions = stay_at_home_county.merge(gather_ban_county, on = ['state', 'county', 'date'], how = 'outer')\n",
    "restrictions = restrictions.merge(mask_mandate_county, on = ['state', 'county', 'date'], how = 'outer')\n",
    "restrictions = restrictions.merge(rest_closure_county, on = ['state', 'county', 'date'], how = 'outer')\n",
    "restrictions = restrictions.merge(bar_closure_county, on = ['state', 'county', 'date'], how = 'outer')\n",
    "restrictions.state.replace(state_dict, inplace = True)\n",
    "date_tmp = np.array(list(restrictions.date.str.split('/')))\n",
    "restrictions['month'] = date_tmp[:,0]\n",
    "restrictions['day'] = date_tmp[:,1]\n",
    "restrictions['year'] = date_tmp[:,2]\n",
    "restrictions.day.replace({'1':'01','2':'02','3':'03','4':'04','5':'05','6':'06','7':'07','8':'08','9':'09',}, inplace = True)\n",
    "restrictions.month.replace({'1':'01','2':'02','3':'03','4':'04','5':'05','6':'06','7':'07','8':'08','9':'09',}, inplace = True)\n",
    "restrictions.drop(columns = ['date'], inplace = True)\n",
    "\n",
    "\n",
    "###########################\n",
    "restrictions.county = restrictions.county.str.lower()\n",
    "restrictions.state = restrictions.state.str.lower()\n",
    "restrictions.county = restrictions.county.str.replace(' county', '')\n",
    "restrictions.county = restrictions.county.str.replace('doña ana', 'dona ana')\n",
    "\n",
    "restrictions = restrictions.drop_duplicates()\n",
    "\n",
    "###########################\n",
    "# rename and recode\n",
    "restrictions = restrictions.rename(columns= {'stayHome_action':'stayAtHomeOrder',\n",
    "                             'gatherBan_action': 'gatherBan',\n",
    "                             'rest_action':'restaurant_restriction',\n",
    "                              'bar_action': 'bar_restriction'})\n",
    "\n",
    "restrictions['stayAtHomeOrder'].replace({'No order for individuals to stay home':0,\n",
    "                                        'Advisory/Recommendation':1,\n",
    "                                        'Mandatory only for at-risk individuals in certain areas of the jurisdiction':2,\n",
    "                                        'Mandatory only for at-risk individuals in the jurisdiction': 3,\n",
    "                                        'Mandatory only for all individuals in certain areas of the jurisdiction':4,\n",
    "                                        'Mandatory for all individuals':5}, inplace = True)\n",
    "\n",
    "restrictions['gatherBan'].replace({'No order found':0,\n",
    "                                  'Ban of gatherings over 101 or more people':1,\n",
    "                                  'Ban of gatherings over 51-100 people':2,\n",
    "                                  'Ban of gatherings over 26-50 people': 3,\n",
    "                                  'Ban of gatherings over 11-25 people':4,\n",
    "                                  'Ban of gatherings over 1-10 people':5,\n",
    "                                  'Bans gatherings of any size': 6}, inplace = True)\n",
    "\n",
    "restrictions['restaurant_restriction'].replace({'Authorized to fully reopen':0,\n",
    "                                               'Open with social distancing/reduced seating/enhanced sanitation':1,\n",
    "                                               'Curbside/carryout/delivery only':2}, inplace = True)\n",
    "\n",
    "restrictions['bar_restriction'].replace({'Authorized to fully reopen':0,\n",
    "                                        'Open with social distancing/reduced seating/enhanced sanitation':1,\n",
    "                                        'Curbside/carryout/delivery only':2,\n",
    "                                        'Closed':3}, inplace = True)\n",
    "\n",
    "# restriction summary measure\n",
    "restrictions['restriction_sum'] = restrictions[['stayAtHomeOrder', 'gatherBan', \n",
    "                                                'restaurant_restriction','bar_restriction']].sum(axis=1)\n",
    "\n",
    "# mean restrictiosn state level \n",
    "col_indlcude = ['state', \n",
    "                'stayAtHomeOrder','gatherBan', 'restaurant_restriction', 'bar_restriction', 'restriction_sum',\n",
    "                'month', 'day', 'year']\n",
    "restrictions_state = restrictions[col_indlcude].groupby(by= ['state', 'month', 'day', 'year']).mean().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a12cc0-681b-4818-bb55-6292c3f2112d",
   "metadata": {},
   "source": [
    "# Anti-Racism Crowd-Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93eb20b-a3d8-4dcc-8b39-a03d2cb25798",
   "metadata": {},
   "outputs": [],
   "source": [
    "arce = pd.read_csv(os.path.join(data_path, 'anti_racism_crowd_events.txt'),low_memory=False, dtype = str, na_values = 'NaN')     \n",
    "# to datetime\n",
    "arce['date'] = pd.to_datetime(arce['date'])\n",
    "# drop irrelevent time frame\n",
    "arce = arce.loc[(arce.date>'2020') & (arce.date<'2022')& (arce.online == '0'),:].reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "arce = arce.loc[(arce.issues.str.find('raci') > 0) | (arce.claims.str.find('raci') > 0), :]\n",
    "arce.reset_index(drop = True, inplace = True)\n",
    "arce['raci_event_count'] = 1\n",
    "\n",
    "# manually add counties\n",
    "idx = arce.location_detail.str.contains('Bronx')\n",
    "idx[idx.isnull()] = False\n",
    "arce.loc[idx,'resolved_county'] =  'Bronx'\n",
    "arce.loc[(arce.locality == 'Richmond') & (arce.state == 'VA'), 'resolved_county'] = 'Richmond'\n",
    "arce.loc[(arce.locality == 'New York') & (arce.state == 'NY'), 'resolved_county'] = 'New York'\n",
    "arce.loc[(arce.locality == 'Baltimore') & (arce.state == 'MD'), 'resolved_county'] = 'Baltimore'\n",
    "arce.loc[(arce.locality == 'Norfolk') & (arce.state == 'VA'), 'resolved_county'] = 'Norfolk'\n",
    "arce.loc[(arce.locality == 'Newport News') & (arce.state == 'VA'), 'resolved_county'] = 'Newport News'\n",
    "arce.loc[(arce.locality == 'Virginia Beach') & (arce.state == 'VA'), 'resolved_county'] = 'Virginia Beach'\n",
    "arce.loc[(arce.locality == 'Suffolk') & (arce.state == 'VA'), 'resolved_county'] = 'Suffolk'\n",
    "arce.loc[(arce.locality == 'St. Louis') & (arce.state == 'MO'), 'resolved_county'] = 'St. Louis'\n",
    "arce.loc[(arce.locality == 'Saint Louis') & (arce.state == 'MO'), 'resolved_county'] = 'St. Louis'\n",
    "arce.loc[(arce.locality == 'Hampton') & (arce.state == 'VA'), 'resolved_county'] = 'Hampton'\n",
    "arce.loc[(arce.locality == 'Harrisonburg') & (arce.state == 'VA'), 'resolved_county'] = 'Harrisonburg'\n",
    "arce.loc[(arce.locality == 'Fredericksburg') & (arce.state == 'VA'), 'resolved_county'] = 'Fredericksburg'\n",
    "arce.loc[(arce.locality == 'Lynchburg') & (arce.state == 'VA'), 'resolved_county'] = 'Lynchburg'\n",
    "arce.loc[(arce.locality == 'Manassas') & (arce.state == 'VA'), 'resolved_county'] = 'Manassas'\n",
    "arce.loc[(arce.locality == 'Portsmouth') & (arce.state == 'VA'), 'resolved_county'] = 'Portsmouth'\n",
    "arce.loc[(arce.locality == 'Roanoke') & (arce.state == 'VA'), 'resolved_county'] = 'Roanoke'\n",
    "arce.loc[(arce.locality == 'Staunton') & (arce.state == 'VA'), 'resolved_county'] = 'Staunton'\n",
    "arce.loc[(arce.locality == 'Williamsburg') & (arce.state == 'VA'), 'resolved_county'] = 'Williamsburg'\n",
    "arce.loc[(arce.locality == 'Winchester') & (arce.state == 'VA'), 'resolved_county'] = 'Winchester'\n",
    "arce.loc[(arce.locality == 'Franklin') & (arce.state == 'VA'), 'resolved_county'] = 'Franklin'\n",
    "arce.loc[(arce.locality == 'Norton') & (arce.state == 'VA'), 'resolved_county'] = 'Norton'\n",
    "arce.loc[(arce.locality == 'Alexandria') & (arce.state == 'VA'), 'resolved_county'] = 'Alexandria'\n",
    "arce.loc[(arce.locality == 'Danville') & (arce.state == 'VA'), 'resolved_county'] = 'Danville'\n",
    "arce.loc[(arce.locality == 'Fairfax') & (arce.state == 'VA'), 'resolved_county'] = 'Fairfax'\n",
    "arce.loc[(arce.locality == 'Galax') & (arce.state == 'VA'), 'resolved_county'] = 'Galax'\n",
    "arce.loc[(arce.locality == 'Lexington') & (arce.state == 'VA'), 'resolved_county'] = 'Lexington'\n",
    "arce.loc[(arce.locality == 'Waynesboro') & (arce.state == 'VA'), 'resolved_county'] = 'Waynesboro'\n",
    "arce.loc[(arce.locality == 'Chesapeake') & (arce.state == 'VA'), 'resolved_county'] = 'Chesapeake'\n",
    "arce.loc[(arce.locality == 'Virgina Beach') & (arce.state == 'VA'), 'resolved_county'] = 'Virgina Beach'\n",
    "arce.loc[(arce.locality == 'Covington') & (arce.state == 'VA'), 'resolved_county'] = 'Covington'\n",
    "arce.loc[(arce.locality == 'Fort Monroe') & (arce.state == 'VA'), 'resolved_county'] = 'Albemarle'\n",
    "arce.loc[(arce.locality == 'Fort Monroe\t') & (arce.state == 'VA'), 'resolved_county'] = ''\n",
    "arce.loc[(arce.locality == 'Salem') & (arce.state == 'VA'), 'resolved_county'] = 'Salem'\n",
    "arce.loc[(arce.locality == 'Radford') & (arce.state == 'VA'), 'resolved_county'] = 'Radford'\n",
    "arce.loc[(arce.locality == 'Petersburg') & (arce.state == 'VA'), 'resolved_county'] = 'Petersburg'\n",
    "arce.loc[(arce.locality == 'Falls Church') & (arce.state == 'VA'), 'resolved_county'] = 'Falls Church'\n",
    "arce.loc[(arce.locality == 'Canton') & (arce.state == 'IL'), 'resolved_county'] = 'Fulton County'\n",
    "arce.loc[(arce.locality == 'Carson City') & (arce.state == 'NV'), 'resolved_county'] = 'Carson City'\n",
    "arce.loc[(arce.locality == 'Wydown') & (arce.state == 'MO'), 'resolved_county'] = 'St. Louis'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# drop irrelevant columns\n",
    "drop_cols = list(arce.columns[arce.columns.str.startswith('source')])\n",
    "drop_cols = drop_cols+list(arce.columns[arce.columns.str.startswith('injuries')])\n",
    "drop_cols = drop_cols+list(arce.columns[arce.columns.str.startswith('police')])\n",
    "drop_cols = drop_cols+list(arce.columns[arce.columns.str.startswith('participant')])\n",
    "drop_cols = drop_cols+list(arce.columns[arce.columns.str.endswith('death')])\n",
    "drop_cols = drop_cols + ['online', 'location_detail', 'locality', 'fips_code', 'lat', 'lon', \n",
    "                         'arrests_any', 'property_damage','resolved_locality',\n",
    "                         'property_damage_any', 'chemical_agents', 'notes', \n",
    "                         'valence', 'macroevent', 'actors', 'organizations', 'type', 'title',\n",
    "                         'size_text','size_low','size_high','size_cat','arrests','claims', 'state', 'issues']\n",
    "arce.drop(columns = drop_cols, inplace = True)\n",
    "\n",
    "arce = pd.DataFrame(arce.groupby(by=['date', 'resolved_county', 'resolved_state'])['raci_event_count'].sum()).reset_index()\n",
    "\n",
    "date_arce_events = np.array(list(arce.date.astype(str).str.split('-')))\n",
    "arce['year'] = date_arce_events[:,0]\n",
    "arce['month'] = date_arce_events[:,1]\n",
    "arce['day'] = date_arce_events[:,2]\n",
    "arce.drop(columns = ['date'], inplace = True)\n",
    "arce.rename(columns = {'resolved_county': 'county', 'resolved_state': 'state'}, inplace = True)\n",
    "arce.state.replace(state_dict, inplace = True)\n",
    "\n",
    "arce_county = arce.copy()\n",
    "arce_state = arce.copy()\n",
    "arce_state = pd.DataFrame(arce_state.groupby(by=['state', 'year','month','day'])['raci_event_count'].sum()).reset_index()\n",
    "arce_state.state = arce_state.state.str.lower()\n",
    "arce_state = arce_state.drop_duplicates()\n",
    "\n",
    "arce_county.county = arce_county.county.str.lower()\n",
    "arce_county.state = arce_county.state.str.lower()\n",
    "arce_county.county = arce_county.county.str.replace(' county', '')\n",
    "arce_county.county = arce_county.county.str.replace('doña ana', 'dona ana')\n",
    "\n",
    "arce_county.county = arce_county.county.str.replace('anchorage', 'anchorage municipality')\n",
    "arce_county.county = arce_county.county.str.replace('baltimore', 'baltimore city')\n",
    "arce_county.county = arce_county.county.str.replace('chesapeake', 'chesapeake city') \n",
    "arce_county.county = arce_county.county.str.replace('denali', 'denali borough')\n",
    "arce_county.county = arce_county.county.str.replace('doòa ana', 'dona ana')\n",
    "arce_county.county = arce_county.county.str.replace('winchester', 'winchester city')\n",
    "arce_county.county = arce_county.county.str.replace('virginia beach', 'virginia beach city')\n",
    "arce_county.county = arce_county.county.str.replace('roanoke', 'roanoke city')\n",
    "arce_county.loc[(arce_county.county=='suffolk') & (arce_county.state=='virginia'), 'county'] = 'suffolk city'\n",
    "arce_county.loc[(arce_county.county=='richmond') & (arce_county.state=='virginia'), 'county'] = 'richmond city'\n",
    "arce_county.loc[(arce_county.county=='norfolk') & (arce_county.state=='virginia'), 'county'] = 'norfolk city'\n",
    "arce_county.loc[(arce_county.county=='newport news') & (arce_county.state=='virginia'), 'county'] = 'newport news city'\n",
    "arce_county.county = arce_county.county.str.replace('fairbanks north star', 'fairbanks north star borough')\n",
    "arce_county = arce_county.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33070382",
   "metadata": {},
   "source": [
    "# Merge all external data on county and state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf3674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_combined = state_data.merge(covid_cumsum_state, on = ['date', 'state'], how = 'left')\n",
    "state_data_combined = state_data_combined.merge(covid_avg_state, on = ['date', 'state'], how = 'left')\n",
    "state_data_combined = state_data_combined.merge(ue_state, on = ['state', 'year', 'month'], how = 'left')\n",
    "state_data_combined = state_data_combined.merge(arce_state, on = ['state', 'year', 'month', 'day'], how = 'left')\n",
    "state_data_combined = state_data_combined.merge(restrictions_state, on = ['state', 'year', 'month', 'day'], how = 'left')\n",
    "\n",
    "county_data_combined = county_data.merge(covid_cumsum_county, on = ['date', 'state', 'county'], how = 'left')\n",
    "county_data_combined = county_data_combined.merge(covid_avg_county, on = ['date', 'state', 'county'], how = 'left')\n",
    "county_data_combined = county_data_combined.merge(arce_county, on = ['state', 'county', 'year', 'month', 'day'], how = 'left')\n",
    "county_data_combined = county_data_combined.merge(restrictions, on = ['state', 'county', 'year', 'month', 'day'], how = 'left')\n",
    "county_data_combined = county_data_combined.merge(ue_county, on = ['state', 'county', 'year', 'month'], how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17850c4f",
   "metadata": {},
   "source": [
    "# merge with pid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5339ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_combined = state_data.merge(state_data_combined, on = ['state','date','year', 'month', 'day'], how = 'left')\n",
    "county_data_combined = pid_county.merge(county_data_combined, on = ['state', 'county','date'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107b476",
   "metadata": {},
   "source": [
    "# save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d09fdf-9cf0-4422-97cb-f2adb3a1369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data_combined.to_csv(os.path.join(out_path, 'externalMeasures_county.csv'), index = False)\n",
    "state_data_combined.to_csv(os.path.join(out_path, 'externalMeasures_state.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd01c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVD_core",
   "language": "python",
   "name": "cvd_core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
